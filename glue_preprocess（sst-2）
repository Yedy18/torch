import os
import pandas as pd
from transformers import BertTokenizer
from tqdm import tqdm
import json

# ===============================
# 1. åŠ è½½æœ¬åœ° tokenizer
# ===============================
tokenizer = BertTokenizer.from_pretrained("/home/zhoushengye/PycharmProjects/pythonProject/bert-base-uncased")

# ===============================
# 2. å®šä¹‰ç¼–ç å‡½æ•°
# ===============================
def encode_batch(texts, max_length=128):
    return tokenizer(
        texts,
        truncation=True,
        padding='max_length',
        max_length=max_length,
        return_tensors=None
    )

# ===============================
# 3. å¤„ç†å•ä¸ªæ–‡ä»¶
# ===============================
def process_sst2_file(input_path, has_labels=True):
    df = pd.read_csv(input_path, sep='\t')

    if has_labels:
        texts = df['sentence'].tolist()
        labels = df['label'].tolist()
    else:
        texts = df['sentence'].tolist()
        labels = [-1] * len(texts)  # testé›†æ— æ ‡ç­¾ï¼Œç”¨-1å ä½

    encodings = encode_batch(texts)

    result = []
    for i in range(len(texts)):
        item = {
            'input_ids': encodings['input_ids'][i],
            'attention_mask': encodings['attention_mask'][i],
            'label': labels[i]
        }
        result.append(item)

    return result

# ===============================
# 4. æ‰§è¡Œé¢„å¤„ç†
# ===============================
root_dir = "/home/zhoushengye/PycharmProjects/pythonProject/raw_glue_data/SST-2"
output_dir = "/home/zhoushengye/PycharmProjects/pythonProject/glue_processed"

os.makedirs(output_dir, exist_ok=True)

print("âœ… æ­£åœ¨å¤„ç† train.tsv ...")
train_data = process_sst2_file(os.path.join(root_dir, "train.tsv"))
with open(os.path.join(output_dir, "train.json"), 'w') as f:
    for item in train_data:
        f.write(json.dumps(item) + "\n")

print("âœ… æ­£åœ¨å¤„ç† dev.tsv ...")
dev_data = process_sst2_file(os.path.join(root_dir, "dev.tsv"))
with open(os.path.join(output_dir, "dev.json"), 'w') as f:
    for item in dev_data:
        f.write(json.dumps(item) + "\n")

print("âœ… æ­£åœ¨å¤„ç† test.tsv ...")
test_data = process_sst2_file(os.path.join(root_dir, "test.tsv"), has_labels=False)
with open(os.path.join(output_dir, "test.json"), 'w') as f:
    for item in test_data:
        f.write(json.dumps(item) + "\n")

print("ğŸ‰ å…¨éƒ¨æ•°æ®å·²é¢„å¤„ç†å®Œæˆï¼Œä¿å­˜åœ¨ glue_processed/ æ–‡ä»¶å¤¹ä¸­ï¼")
